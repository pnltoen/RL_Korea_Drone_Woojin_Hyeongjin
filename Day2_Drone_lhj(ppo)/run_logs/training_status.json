{
    "My Behavior": {
        "checkpoints": [
            {
                "steps": 12499970,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-12499970.onnx",
                "reward": 2.5057083149440587,
                "creation_time": 1636418342.9532256,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-12499970.pt"
                ]
            },
            {
                "steps": 12999943,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-12999943.onnx",
                "reward": 2.3854272831231356,
                "creation_time": 1636425972.6113086,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-12999943.pt"
                ]
            },
            {
                "steps": 13499938,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-13499938.onnx",
                "reward": 3.1689873271518283,
                "creation_time": 1636433733.3915055,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-13499938.pt"
                ]
            },
            {
                "steps": 13999955,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-13999955.onnx",
                "reward": 3.1268157362937927,
                "creation_time": 1636441614.069476,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-13999955.pt"
                ]
            },
            {
                "steps": 14000019,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-14000019.onnx",
                "reward": 3.1268157362937927,
                "creation_time": 1636441614.3428307,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-14000019.pt"
                ]
            },
            {
                "steps": 14499953,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-14499953.onnx",
                "reward": 3.164895678471242,
                "creation_time": 1636454689.6062102,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-14499953.pt"
                ]
            },
            {
                "steps": 14999942,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-14999942.onnx",
                "reward": 2.370067867760857,
                "creation_time": 1636462671.5470822,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-14999942.pt"
                ]
            },
            {
                "steps": 15499948,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-15499948.onnx",
                "reward": 2.766919946044006,
                "creation_time": 1636470549.8607628,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-15499948.pt"
                ]
            },
            {
                "steps": 15999980,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-15999980.onnx",
                "reward": 3.1589926332235336,
                "creation_time": 1636478379.217584,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-15999980.pt"
                ]
            },
            {
                "steps": 16499958,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-16499958.onnx",
                "reward": 3.128846234331528,
                "creation_time": 1636486152.8615203,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-16499958.pt"
                ]
            },
            {
                "steps": 16999982,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-16999982.onnx",
                "reward": 2.9360497029567205,
                "creation_time": 1636493934.452034,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-16999982.pt"
                ]
            },
            {
                "steps": 17499973,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-17499973.onnx",
                "reward": 2.813289850950241,
                "creation_time": 1636501679.208086,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-17499973.pt"
                ]
            },
            {
                "steps": 17999995,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-17999995.onnx",
                "reward": 2.743865410486857,
                "creation_time": 1636509478.410318,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-17999995.pt"
                ]
            },
            {
                "steps": 18465101,
                "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-18465101.onnx",
                "reward": 3.122077465057373,
                "creation_time": 1636516799.6900938,
                "auxillary_file_paths": [
                    "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-18465101.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 18465101,
            "file_path": "results\\Day2_Drone_lhj(ppo)\\My Behavior.onnx",
            "reward": 3.122077465057373,
            "creation_time": 1636516799.6900938,
            "auxillary_file_paths": [
                "results\\Day2_Drone_lhj(ppo)\\My Behavior\\My Behavior-18465101.pt"
            ]
        }
    },
    "metadata": {
        "stats_format_version": "0.3.0",
        "mlagents_version": "0.27.0",
        "torch_version": "1.10.0"
    }
}