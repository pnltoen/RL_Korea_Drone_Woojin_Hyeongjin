{
    "My Behavior": {
        "checkpoints": [
            {
                "steps": 499948,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-499948.onnx",
                "reward": 1.1822061292827128,
                "creation_time": 1636657172.057024,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-499948.pt"
                ]
            },
            {
                "steps": 999950,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-999950.onnx",
                "reward": null,
                "creation_time": 1636665184.4953864,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-999950.pt"
                ]
            },
            {
                "steps": 1499974,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-1499974.onnx",
                "reward": 4.493118281732313,
                "creation_time": 1636673130.88347,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-1499974.pt"
                ]
            },
            {
                "steps": 1999963,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-1999963.onnx",
                "reward": 4.102967497677757,
                "creation_time": 1636681099.7403111,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-1999963.pt"
                ]
            },
            {
                "steps": 2499992,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-2499992.onnx",
                "reward": 3.336232613772154,
                "creation_time": 1636688989.051681,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-2499992.pt"
                ]
            },
            {
                "steps": 2999982,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-2999982.onnx",
                "reward": 0.7908956691389903,
                "creation_time": 1636696086.375689,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-2999982.pt"
                ]
            },
            {
                "steps": 3499948,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-3499948.onnx",
                "reward": 4.992645462354024,
                "creation_time": 1636703245.64964,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-3499948.pt"
                ]
            },
            {
                "steps": 3999919,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-3999919.onnx",
                "reward": 6.448419667780399,
                "creation_time": 1636710410.3201451,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-3999919.pt"
                ]
            },
            {
                "steps": 4499954,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-4499954.onnx",
                "reward": 3.8891298374575047,
                "creation_time": 1636717454.333053,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-4499954.pt"
                ]
            },
            {
                "steps": 4999928,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-4999928.onnx",
                "reward": 4.822802434364955,
                "creation_time": 1636724549.687087,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-4999928.pt"
                ]
            },
            {
                "steps": 5499916,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-5499916.onnx",
                "reward": 2.567220342811197,
                "creation_time": 1636731836.606798,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-5499916.pt"
                ]
            },
            {
                "steps": 5999984,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-5999984.onnx",
                "reward": 5.241554310545325,
                "creation_time": 1636739139.8432627,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-5999984.pt"
                ]
            },
            {
                "steps": 6499898,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-6499898.onnx",
                "reward": 6.608246978457001,
                "creation_time": 1636746421.2904444,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-6499898.pt"
                ]
            },
            {
                "steps": 6999943,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-6999943.onnx",
                "reward": 4.917197331786156,
                "creation_time": 1636753704.083002,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-6999943.pt"
                ]
            },
            {
                "steps": 7499873,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-7499873.onnx",
                "reward": 3.545175417429871,
                "creation_time": 1636760991.779932,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-7499873.pt"
                ]
            },
            {
                "steps": 7999988,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-7999988.onnx",
                "reward": 6.6841564774513245,
                "creation_time": 1636768253.0843816,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-7999988.pt"
                ]
            },
            {
                "steps": 8499922,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-8499922.onnx",
                "reward": 10.939655093062255,
                "creation_time": 1636775542.2066822,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-8499922.pt"
                ]
            },
            {
                "steps": 8999985,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-8999985.onnx",
                "reward": 7.34858696659406,
                "creation_time": 1636782976.107439,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-8999985.pt"
                ]
            },
            {
                "steps": 9499937,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-9499937.onnx",
                "reward": 8.95576005615294,
                "creation_time": 1636790922.9328725,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-9499937.pt"
                ]
            },
            {
                "steps": 9926020,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-9926020.onnx",
                "reward": null,
                "creation_time": 1636797242.7999854,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-9926020.pt"
                ]
            },
            {
                "steps": 9999989,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-9999989.onnx",
                "reward": 6.428546802140772,
                "creation_time": 1636799049.912051,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-9999989.pt"
                ]
            },
            {
                "steps": 10499999,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-10499999.onnx",
                "reward": 6.871762779964642,
                "creation_time": 1636806245.6337252,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-10499999.pt"
                ]
            },
            {
                "steps": 10999982,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-10999982.onnx",
                "reward": 8.454510724970273,
                "creation_time": 1636813409.2225244,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-10999982.pt"
                ]
            },
            {
                "steps": 11499899,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-11499899.onnx",
                "reward": 7.210114063147237,
                "creation_time": 1636821426.8505118,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-11499899.pt"
                ]
            },
            {
                "steps": 11999909,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-11999909.onnx",
                "reward": 9.60454933983939,
                "creation_time": 1636828596.9177804,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-11999909.pt"
                ]
            },
            {
                "steps": 12499976,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-12499976.onnx",
                "reward": 7.871442772448063,
                "creation_time": 1636835754.552893,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-12499976.pt"
                ]
            },
            {
                "steps": 12999952,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-12999952.onnx",
                "reward": 5.628747976488537,
                "creation_time": 1636842900.6922376,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-12999952.pt"
                ]
            },
            {
                "steps": 13499999,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-13499999.onnx",
                "reward": -0.3229962054711695,
                "creation_time": 1636850089.4182122,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-13499999.pt"
                ]
            },
            {
                "steps": 13648353,
                "file_path": "results\\beta_0.04_linear\\My Behavior\\My Behavior-13648353.onnx",
                "reward": 0.4228374660273807,
                "creation_time": 1636852308.996059,
                "auxillary_file_paths": [
                    "results\\beta_0.04_linear\\My Behavior\\My Behavior-13648353.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 13648353,
            "file_path": "results\\beta_0.04_linear\\My Behavior.onnx",
            "reward": 0.4228374660273807,
            "creation_time": 1636852308.996059,
            "auxillary_file_paths": [
                "results\\beta_0.04_linear\\My Behavior\\My Behavior-13648353.pt"
            ]
        }
    },
    "metadata": {
        "stats_format_version": "0.3.0",
        "mlagents_version": "0.26.0",
        "torch_version": "1.9.0+cu111"
    }
}